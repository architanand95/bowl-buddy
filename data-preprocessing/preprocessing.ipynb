{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Use SAM for Image Segmentation\n",
    "# 2. Use Pose Detection to find the pose of the person\n",
    "# 3. Segment Diffrent parts of the body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read From directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class ReadBuddy:\n",
    "    def __init__(self, parent_directory):\n",
    "        self.parent_directory = parent_directory\n",
    "        \n",
    "\n",
    "    def create_folder_dictionary(self, new_path=None):\n",
    "        \n",
    "        folder_dict = {}\n",
    "        \n",
    "        new_folder_dict = {}\n",
    "        \n",
    "        for folder in os.listdir(self.parent_directory):\n",
    "            \n",
    "            folder_path = os.path.join(self.parent_directory, folder)\n",
    "            \n",
    "            if new_path:\n",
    "                new_folder_path = os.path.join(new_path, folder)\n",
    "                new_file_array=[]\n",
    "            \n",
    "            file_array = []\n",
    "            \n",
    "            for file in os.listdir(folder_path):\n",
    "                \n",
    "                if new_path:\n",
    "                    new_file_path = os.path.join(new_folder_path, file)\n",
    "                    new_file_array.append(new_file_path)\n",
    "                \n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                file_array.append(file_path)\n",
    "                \n",
    "            folder_dict[folder] = file_array\n",
    "            \n",
    "            if new_path:\n",
    "                new_folder_dict[folder] = new_file_array\n",
    "                \n",
    "            \n",
    "\n",
    "        return folder_dict,new_folder_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detector class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-23 20:53:14] INFO - checkpoint_utils.py - License Notification: YOLO-NAS pre-trained weights are subjected to the specific license terms and conditions detailed in \n",
      "https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.YOLONAS.md\n",
      "By downloading the pre-trained weight files you agree to comply with these terms.\n"
     ]
    }
   ],
   "source": [
    "from super_gradients.training import models\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "class DetectBuddy:\n",
    "    def __init__(self, model_name='yolo_nas_l', weights='coco', conf_threshold=0.8):\n",
    "        self.model = models.get(model_name, pretrained_weights=weights)\n",
    "        self.conf_threshold = conf_threshold\n",
    "        self.detection_list = []\n",
    "        \n",
    "    def predict_human(self, image_path_or_array, show=False):\n",
    "        if isinstance(image_path_or_array, str):\n",
    "            \n",
    "            image = cv2.imread(image_path_or_array)\n",
    "        else:\n",
    "           \n",
    "            image = image_path_or_array\n",
    "            \n",
    "        prediction = self.model.predict(image, conf=self.conf_threshold)\n",
    "        \n",
    "        if show:\n",
    "            prediction.show()\n",
    "        \n",
    "        detection_pred = prediction._images_prediction_lst\n",
    "        self.detection_list = list(detection_pred)\n",
    "\n",
    "\n",
    "detect= DetectBuddy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from segment_anything import sam_model_registry\n",
    "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from super_gradients.training import models\n",
    "from segment_anything import  SamPredictor\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "class SegmentBuddy():\n",
    "    \n",
    "    ##### CODE FROM DOCUMENTATION #####\n",
    "    def show_mask(mask, ax, random_color=False):\n",
    "        if random_color:\n",
    "            color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "        else:\n",
    "            color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "        h, w = mask.shape[-2:]\n",
    "        mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "        ax.imshow(mask_image)\n",
    "\n",
    "    def show_points(coords, labels, ax, marker_size=375):\n",
    "        pos_points = coords[labels==1]\n",
    "        neg_points = coords[labels==0]\n",
    "        ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "        ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "\n",
    "    def show_box(box, ax):\n",
    "        x0, y0 = box[0], box[1]\n",
    "        w, h = box[2] - box[0], box[3] - box[1]\n",
    "        ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0, 0, 0, 0), lw=2))\n",
    "\n",
    "    def show_anns(anns):\n",
    "        if len(anns) == 0:\n",
    "            return\n",
    "        sorted_anns = sorted(anns, key=lambda x: x['area'], reverse=True)\n",
    "        ax = plt.gca()\n",
    "        ax.set_autoscale_on(False)\n",
    "        polygons = []\n",
    "        for ann in sorted_anns:\n",
    "            m = ann['segmentation']\n",
    "            img = np.ones((m.shape[0], m.shape[1], 3))\n",
    "            color_mask = np.random.random((1, 3)).tolist()[0]\n",
    "            for i in range(3):\n",
    "                img[:, :, i] = color_mask[i]\n",
    "            ax.imshow(np.dstack((img, m * 0.35)))\n",
    "            \n",
    "    ##### CODE FROM DOCUMENTATION #####\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self,path_to_checkpoints, model_type=\"vit_h\",device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        \n",
    "        self.sam = sam_model_registry[model_type] (checkpoint=path_to_checkpoints)\n",
    "        self.sam.to (device=device)\n",
    "        \n",
    "        self.mask_generator = SamAutomaticMaskGenerator (self.sam)\n",
    "        \n",
    "        self.predictor = SamPredictor(self.sam)\n",
    "            \n",
    "            \n",
    "    def segment_person(self,image_path,show_mask=False):\n",
    "        \n",
    "        \n",
    "        detect.predict_human(image_path)\n",
    "\n",
    "        \n",
    "        detection_list = detect.detection_list\n",
    "\n",
    "        \n",
    "        bboxes_xyxy = detection_list[0].prediction.bboxes_xyxy.tolist()\n",
    "        labels = detection_list[0].prediction.labels.tolist()\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        masks = self.mask_generator.generate(image)\n",
    "\n",
    "        self.predictor.set_image(image)\n",
    "\n",
    "        image = image.transpose((2, 0, 1))  # Transpose to match SAM input format\n",
    "        image = image / 255.0  # Normalize image values to [0, 1]\n",
    "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "        input_box = np.array(bboxes_xyxy[0])\n",
    "        \n",
    "        if labels[0] == 0:\n",
    "           \n",
    "            masks, _, _ = self.predictor.predict(\n",
    "                point_coords=None,\n",
    "                point_labels=None,\n",
    "                box=input_box[None, :],\n",
    "                multimask_output=False,\n",
    "            )\n",
    "    \n",
    "        masked_image = cv2.bitwise_and(image[0].transpose((1, 2, 0)), image[0].transpose((1, 2, 0)), mask=masks[0].astype(np.uint8))\n",
    "        \n",
    "        \n",
    "        if show_mask:\n",
    "            plt.imshow(image[0].transpose((1, 2, 0)))\n",
    "            if labels[0] == 0:\n",
    "                plt.imshow(masks[0], alpha=0.5)\n",
    "                \n",
    "       \n",
    "        return masked_image\n",
    "\n",
    "        \n",
    "segmentor=SegmentBuddy(\"../resources/sam_vit_h_4b8939.pth\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentor.segment_person(\"../preprocessed-data/bad_ankel_left/0.jpg\",show_mask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../preprocessed-data/bad_ankle_right/35.jpg done\n",
      "../preprocessed-data/bad_ankle_right/57.jpg done\n",
      "../preprocessed-data/bad_ankle_right/26.jpg done\n",
      "../preprocessed-data/bad_ankle_right/24.jpg done\n",
      "../preprocessed-data/bad_ankle_right/54.jpg done\n",
      "../preprocessed-data/bad_ankle_right/50.jpg done\n",
      "../preprocessed-data/bad_ankle_right/38.jpg done\n",
      "../preprocessed-data/bad_ankle_right/4.jpg done\n",
      "../preprocessed-data/bad_ankle_right/37.jpg done\n",
      "../preprocessed-data/bad_ankle_right/9.jpg done\n",
      "../preprocessed-data/bad_ankle_right/39.jpg done\n",
      "../preprocessed-data/bad_ankle_right/2.jpg done\n",
      "../preprocessed-data/bad_ankle_right/16.jpg done\n",
      "../preprocessed-data/bad_ankle_right/7.jpg done\n",
      "../preprocessed-data/bad_ankle_right/45.jpg done\n",
      "../preprocessed-data/bad_ankle_right/29.jpg done\n",
      "../preprocessed-data/bad_ankle_right/44.jpg done\n",
      "../preprocessed-data/bad_ankle_right/40.jpg done\n",
      "../preprocessed-data/bad_ankle_right/51.jpg done\n",
      "../preprocessed-data/bad_ankle_right/6.jpg done\n",
      "../preprocessed-data/bad_ankle_right/10.jpg done\n",
      "../preprocessed-data/bad_ankle_right/42.jpg done\n",
      "../preprocessed-data/bad_ankle_right/31.jpg done\n",
      "../preprocessed-data/bad_ankle_right/30.jpg done\n",
      "../preprocessed-data/bad_ankle_right/33.jpg done\n",
      "../preprocessed-data/bad_ankle_right/36.jpg done\n",
      "../preprocessed-data/bad_ankle_right/14.jpg done\n",
      "../preprocessed-data/bad_ankle_right/8.jpg done\n",
      "../preprocessed-data/bad_ankle_right/58.jpg done\n",
      "../preprocessed-data/bad_ankle_right/22.jpg done\n",
      "../preprocessed-data/bad_ankle_right/43.jpg done\n",
      "../preprocessed-data/bad_ankle_right/0.jpg done\n",
      "../preprocessed-data/bad_ankle_right/48.jpg done\n",
      "../preprocessed-data/bad_ankle_right/23.jpg done\n",
      "../preprocessed-data/bad_ankle_right/13.jpg done\n",
      "../preprocessed-data/bad_ankle_right/18.jpg done\n",
      "../preprocessed-data/bad_ankle_right/34.jpg done\n",
      "../preprocessed-data/bad_ankle_right/28.jpg done\n",
      "../preprocessed-data/bad_ankle_right/25.jpg done\n",
      "../preprocessed-data/bad_ankle_right/47.jpg done\n",
      "../preprocessed-data/bad_ankle_right/1.jpg done\n",
      "../preprocessed-data/bad_ankle_right/55.jpg done\n",
      "../preprocessed-data/bad_ankle_right/27.jpg done\n",
      "../preprocessed-data/bad_ankle_right/5.jpg done\n",
      "../preprocessed-data/bad_ankle_right/49.jpg done\n",
      "../preprocessed-data/bad_ankle_right/52.jpg done\n",
      "../preprocessed-data/bad_ankle_right/15.jpg done\n",
      "../preprocessed-data/bad_ankle_right/3.jpg done\n",
      "../preprocessed-data/bad_ankle_right/19.jpg done\n",
      "../preprocessed-data/bad_ankle_right/46.jpg done\n",
      "../preprocessed-data/bad_ankle_right/32.jpg done\n",
      "../preprocessed-data/bad_ankle_right/41.jpg done\n",
      "../preprocessed-data/bad_ankle_right/53.jpg done\n",
      "../preprocessed-data/bad_ankle_right/11.jpg done\n",
      "../preprocessed-data/bad_ankle_right/20.jpg done\n",
      "../preprocessed-data/bad_ankle_right/56.jpg done\n",
      "../preprocessed-data/bad_ankle_right/12.jpg done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../preprocessed-data/bad_ankle_right/17.jpg done\n",
      "bad_ankle_right done\n"
     ]
    }
   ],
   "source": [
    "reader=ReadBuddy(\"../preprocessed-data\")\n",
    "\n",
    "folder_dict=reader.create_folder_dictionary()\n",
    "# print(folder_dict)\n",
    "\n",
    "new_folder= \"../preprocessed-data-masked\"\n",
    "\n",
    "# sort \n",
    "img_dict={}\n",
    "for folder in folder_dict:\n",
    "    \n",
    "    image_array=[]\n",
    "    for file in folder_dict[folder]:\n",
    "        masked_image=segmentor.segment_person(file)\n",
    "        print(file+ \" done\")\n",
    "        \n",
    "    \n",
    "        masked_image=masked_image*255\n",
    "        masked_image=masked_image.astype(np.uint8)\n",
    "        \n",
    "        cv2.imwrite(file,masked_image)\n",
    "        \n",
    "        image_array.append(masked_image)\n",
    "        \n",
    "    print(folder+\" done\")\n",
    "    \n",
    "    img_dict[folder]=image_array\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for key in img_dict:\n",
    "    for image in img_dict[key]:\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"../preprocessed-data-masked\")\n",
    "except:\n",
    "    pass\n",
    "reader=ReadBuddy(\"../preprocessed-data\")\n",
    "\n",
    "\n",
    "old_dict,new_dict=reader.create_folder_dictionary(\"../preprocessed-data-masked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad_ankle_right 58\n",
      "bad_ankel_left 33\n",
      "good_ankle 53\n",
      "['bad_ankel_left', 'good_ankle']\n",
      "['bad_ankle_right']\n"
     ]
    }
   ],
   "source": [
    "keys=list(old_dict.keys())\n",
    "# keys.sort()\n",
    "\n",
    "sampurn_slice=keys[1:]\n",
    "pratyush_slice=[keys[0]]\n",
    "\n",
    "for key in keys:\n",
    "    old_dict[key].sort()\n",
    "    \n",
    "    print(key +  \" \" +str(len(old_dict[key])))\n",
    "    \n",
    "    \n",
    "print(sampurn_slice)\n",
    "print(pratyush_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keys in sampurn_slice:\n",
    "    for i in range(len(old_dict[keys])):\n",
    "            \n",
    "            \n",
    "            masked_image=segmentor.segment_person(old_dict[keys][i])\n",
    "            masked_image=masked_image*255\n",
    "            masked_image=masked_image.astype(np.uint8)\n",
    "            \n",
    "            cv2.imwrite(new_dict[keys][i],masked_image)\n",
    "            \n",
    "            \n",
    "            print(old_dict[keys][i]+ \"-->\"+ new_dict[keys][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keys in pratyush_slice:\n",
    "    for i in range(len(old_dict[keys])):\n",
    "            \n",
    "            \n",
    "            masked_image=segmentor.segment_person(old_dict[keys][i])\n",
    "            masked_image=masked_image*255\n",
    "            masked_image=masked_image.astype(np.uint8)\n",
    "            \n",
    "            cv2.imwrite(new_dict[keys][i],masked_image)\n",
    "            \n",
    "            \n",
    "            print(old_dict[keys][i]+ \"-->\"+ new_dict[keys][i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
